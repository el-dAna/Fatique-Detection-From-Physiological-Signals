"""
Sessions outline 

Relax = 5*60 secs
PhysicalStress = 6*60
Relax = 5*60
MiniCognitiveStress = 40
CognitiveStress = 5*60
Relax = 5*60
EmotionalStress = 5*60
Relax = 5*60
"""



started docker image build but encountered errors. 


Challenges.
Running a standalone streamlit app was smooth. Packaging and running docker image had some session states apparently not initialised! uff! I changed the running port to default streamlit 8501 and it worked. 

authenticating codespaces with ecs in order to build and push image. codepaces is not a non TTY device. So i used local env to communicate with my ecs repositories. Cloud9 was not used because space on the free tier devices was not enough for pakages in requirements.txt. I got "WARNING! Using --password via the CLI is insecure. Use --password-stdin." Will use IAM role/policies in future. 
The solution was to create IAM role and attach needed policies(full access to ecs registry), then save the ID and secrete access keys of the role by running aws config on cli. Then after commands from the private ecs repository were run. Boom! To communicate with s3 bucket I added corresponding policy to the same IAM role created for ecs access. I just added full access to s3 bucket policy. I will change this later to readonly when published.

Deploy container to AWS Apprunner. Check that the port specified in the docker file is same in app runner config.

## Running inference
The idea is for users to train a new model
[change model parameters like input shape, dropout rates, loss, optimiser, epochs, train steps....] and data processing options like sampling window, degree of overlap beteen samples. Users can also determine percent of train data to use. All this via an api on the fly and see results on clearml
Save it to clearml / s3 bucket
And reload the model
Run inference. 

I think saving on clearml is more practical since models on s3 would have to be downloaded and saved explicitly in a file system. Clearml handles all this by calling a method. Will fully swith to clearml

Tagged model selection
Structure of trained models differ in their input shape based on the sample window selected during training. The input shape of architecture changes to accomodate the sample window. So it is important for users to be able to choose such models and process the subject data accordingly and then use uplaoded model for inference. All models are loaded if no compatible model is found and inference made using default specifications (sampling_window=100, overlap=0.5) 

## Next session
present file descriptions in tabular form, heading(file names), rows(recorded info, frequency, #samples, ....)
load models based on selected tags and run inference
smooth linkage b/n pages. Currently some part of data preprocessing has to work before inference page works smoothly

---------------------------------------------------------------
## TO DOs before full deployment
put access key and secrete access key of generated policy and environment vars. can os... access env variables in any server

why not deployed on streaamlit-> clearml would need to authentication. Maybe a script to execute terminal commands and pass in values saved as env vars accessed using os
same issue with Apprunner
will deploy on ec2 since these can be done from terminal and app kept running

____________________________________________________________________
numpy
matplotlib
joblib==1.3.2
scipy==1.10.1
Cython==3.0.5
keras==2.13.1
tensorflow==2.13.1
pandas==2.0.3
pylint
black
pytest==7.4.3
jsons==1.6.3

#fastapi
fastapi==0.103.2
pydantic==1.10.13
uvicorn[standard]==0.25.0
python-multipart==0.0.6

#access s3 bucket data
s3fs==2023.10.0
boto3

# wl module
PyWavelets==1.4.1
scikit-learn==1.3.2

#general
mlflow==2.8.1
clearml==1.13.2

#app
streamlit==1.29.0
seaborn==0.13.0
streamlit-extras==0.3.6

